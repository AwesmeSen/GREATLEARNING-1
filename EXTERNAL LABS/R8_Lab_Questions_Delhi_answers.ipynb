{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "R8_Lab_Questions_Delhi_answers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "NFfDTfhlaEI_"
      },
      "source": [
        "# Transfer Learning MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "rNwbqCFRaEJC"
      },
      "source": [
        "* Train a simple convnet on the MNIST dataset the first 5 digits [0-4].\n",
        "* Freeze convolutional layers and fine-tune dense layers for the classification of digits [5-9]."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Dnzaw1i5sXF",
        "colab_type": "text"
      },
      "source": [
        "## MNIST Dataset\n",
        "The MNIST database contains 60,000 training images and 10,000 testing images taken from American Census Bureau employees and American high school students. The MNIST dataset is one of the most common datasets used for image classification and accessible from many different sources. In fact, even Tensorflow and Keras allow us to import and download the MNIST dataset directly from their API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpUULy1Z5sXF",
        "colab_type": "text"
      },
      "source": [
        "Let's import keras and load MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiG7IPhm5sXG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Initialize the random number generator\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqUiJM_Z5sXL",
        "colab_type": "code",
        "outputId": "8731e377-1b1f-4a58-bfd8-4729983c52e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        }
      },
      "source": [
        "from keras.backend import backend\n",
        "from keras.datasets import mnist\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVw4wsuW5sXO",
        "colab_type": "text"
      },
      "source": [
        "X_train and X_test contain greyscale RGB codes (from 0 to 255) while y_train and y_test contains labels from 0 to 9 which represents which number they actually are."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgQ86Vhw5sXP",
        "colab_type": "text"
      },
      "source": [
        "Let's visualize some numbers using matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ_Lfjm4hOCJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ac6884d-5985-4d9a-c9bd-5bac1d073395"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZwg00gO5sXQ",
        "colab_type": "code",
        "outputId": "05eb047d-4aca-408f-efae-82440ac1af64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "print(\"Label: {}\".format(y_train[1000]))\n",
        "plt.imshow(X_train[1000], cmap='gray')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fcab4ff69e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p64mhwp95sXS",
        "colab_type": "text"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XxNAiWYd5sXT",
        "colab_type": "text"
      },
      "source": [
        "### Create two datasets\n",
        "- First having digits from 0 to 4\n",
        "- Second having digits from 5 to 9\n",
        "\n",
        "Hint: use labels to separate data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhl-bcjbWEkZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_0_4 = []\n",
        "y_train_0_4 = []\n",
        "X_train_5_9 = []\n",
        "y_train_5_9 = []\n",
        "for i in range(0,y_train.shape[0]):\n",
        "  if y_train[i] in [0,1,2,3,4]:\n",
        "    X_train_0_4.append(X_train[i])\n",
        "    y_train_0_4.append(y_train[i])\n",
        "  else:\n",
        "      X_train_5_9.append(X_train[i])\n",
        "      y_train_5_9.append(y_train[i])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1807m1CL5sXT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test_0_4 = []\n",
        "y_test_0_4 = []\n",
        "X_test_5_9 = []\n",
        "y_test_5_9 = []\n",
        "for i in range(0,y_test.shape[0]):\n",
        "  if y_test[i] in [0,1,2,3,4]:\n",
        "    X_test_0_4.append(X_test[i])\n",
        "    y_test_0_4.append(y_test[i])\n",
        "  else:\n",
        "      X_test_5_9.append(X_test[i])\n",
        "      y_test_5_9.append(y_test[i])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhO8L0x4ZOP2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "X_train_0_4 = np.array(X_train_0_4)\n",
        "y_train_0_4 = np.array(y_train_0_4)\n",
        "X_train_5_9 = np.array(X_train_5_9)\n",
        "y_train_5_9 = np.array(y_train_5_9)\n",
        "\n",
        "X_test_0_4 = np.array(X_test_0_4)\n",
        "y_test_0_4 = np.array(y_test_0_4)\n",
        "X_test_5_9 = np.array(X_test_5_9)\n",
        "y_test_5_9 = np.array(y_test_5_9)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9jKcF1z5sXV",
        "colab_type": "text"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NMo7lvwQ5sXW",
        "colab_type": "text"
      },
      "source": [
        "### Print shape of the data\n",
        "- print shape of all variables of both the datasets you created"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kH7ZjEoH5sXW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "7d219245-d28d-4de6-bb61-e576fc365678"
      },
      "source": [
        "print(\"Shape of X_train_0_4 is - \",X_train_0_4.shape)\n",
        "print(\"Shape of y_train_0_4 is - \",y_train_0_4.shape)\n",
        "print(\"Shape of X_test_0_4 is - \",X_test_0_4.shape)\n",
        "print(\"Shape of y_test_0_4 is - \",y_test_0_4.shape)\n",
        "print(\"====\"*10)\n",
        "print(\"Shape of X_train_5_9 is - \",X_train_5_9.shape)\n",
        "print(\"Shape of y_train_5_9 is - \",y_train_5_9.shape)\n",
        "print(\"Shape of X_test_5_9 is - \",X_test_5_9.shape)\n",
        "print(\"Shape of X_test_5_9 is - \",y_test_5_9.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_train_0_4 is -  (30596, 28, 28)\n",
            "Shape of y_train_0_4 is -  (30596,)\n",
            "Shape of X_test_0_4 is -  (5139, 28, 28)\n",
            "Shape of y_test_0_4 is -  (5139,)\n",
            "========================================\n",
            "Shape of X_train_5_9 is -  (29404, 28, 28)\n",
            "Shape of y_train_5_9 is -  (29404,)\n",
            "Shape of X_test_5_9 is -  (4861, 28, 28)\n",
            "Shape of X_test_5_9 is -  (4861,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IUU4PkKU5sXY",
        "colab_type": "text"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I8ajqdt5sXY",
        "colab_type": "text"
      },
      "source": [
        "### Reshape data\n",
        "- reshape first dataset\n",
        "- To be able to use the dataset in Keras, we need 4-dims numpy arrays. \n",
        "- reshape features to pass it to a Conv2D layer\n",
        "- channel = 1\n",
        "- reshape features of first dataset only\n",
        "- do not reshape labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38wgBEcz5sXa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX_0_4 = X_train_0_4.reshape(X_train_0_4.shape[0], 28, 28,1 ).astype('float32')\n",
        "testX_0_4 = X_test_0_4.reshape(X_test_0_4.shape[0], 28, 28,1 ).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5H-BtNm5sXg",
        "colab_type": "text"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ahCMtCl5sXh",
        "colab_type": "text"
      },
      "source": [
        "### Normalize data\n",
        "- normalize first dataset\n",
        "- we must normalize our data as it is always required in neural network models\n",
        "- we can achieve this by dividing the RGB codes to 255 (which is the maximum RGB code minus the minimum RGB code)\n",
        "- normalize X_train and X_test\n",
        "- make sure that the values are float so that we can get decimal points after division"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4mti7pg5sXj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX_0_4 /= 255\n",
        "testX_0_4 /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfQ6545D5sXp",
        "colab_type": "text"
      },
      "source": [
        "### Print shape of data and number of images\n",
        "- for first dataset\n",
        "- print shape of X_train\n",
        "- print number of images in X_train\n",
        "- print number of images in X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQfQXZMo5sXp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57bc9a43-e34d-482f-9303-d1906349d1ad"
      },
      "source": [
        "trainX_0_4.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30596, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRTlEZa1fdli",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e48cafee-e843-43e2-acb6-d944ac650829"
      },
      "source": [
        "trainX_0_4.shape[0]"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30596"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhwklU8-fmFD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be534ef4-94ce-425d-dfcb-cbf440df27cd"
      },
      "source": [
        "testX_0_4.shape[0]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5139"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oFjomSh5sXu",
        "colab_type": "text"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lEFQQNk5sXu",
        "colab_type": "text"
      },
      "source": [
        "### One-hot encode the class vector\n",
        "- encode labels of first dataset\n",
        "- convert class vectors (integers) to binary class matrix\n",
        "- convert y_train and y_test\n",
        "- number of classes: 5\n",
        "- we are doing this to use categorical_crossentropy as loss\n",
        "\n",
        "Hint: you can use keras.utils.to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aejx3Zb35sXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        "trainY_0_4  = np_utils.to_categorical(y_train_0_4, 5)\n",
        "testY_0_4  = np_utils.to_categorical(y_test_0_4 , 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kqT4V9WgqKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.datasets import cifar10, mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
        "from keras.layers import Convolution2D, MaxPooling2D\n",
        "from keras.utils import np_utils\n",
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "plt.rcParams['figure.figsize'] = (15, 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUKQyJxogp04",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlkiipRA5sXw",
        "colab_type": "text"
      },
      "source": [
        "## Question 6\n",
        "We will build our model by using high level Keras."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzYMC_xm5sXx",
        "colab_type": "text"
      },
      "source": [
        "### Initialize a sequential model\n",
        "- define a sequential model\n",
        "- add 2 convolutional layers\n",
        "    - no of filters: 32\n",
        "    - kernel size: 3x3\n",
        "    - activation: \"relu\"\n",
        "    - input shape: (28, 28, 1) for first layer\n",
        "- add a max pooling layer of size 2x2\n",
        "- add a dropout layer\n",
        "    - dropout layers fight with the overfitting by disregarding some of the neurons while training\n",
        "    - use dropout rate 0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2RaPWiP5sXz",
        "colab_type": "text"
      },
      "source": [
        "## Question 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ajGIM6t5sXz",
        "colab_type": "text"
      },
      "source": [
        "### Add classification layers\n",
        "- do this after doing question 6\n",
        "- flatten the data\n",
        "    - add Flatten later\n",
        "    - flatten layers flatten 2D arrays to 1D array before building the fully connected layers\n",
        "- add 2 dense layers\n",
        "    - number of neurons in first layer: 128\n",
        "    - number of neurons in last layer: number of classes\n",
        "    - activation function in first layer: relu\n",
        "    - activation function in last layer: softmax\n",
        "    - we may experiment with any number of neurons for the first Dense layer; however, the final Dense layer must have neurons equal to the number of output classes\n",
        "- you can add a dropout layer in between, if necessary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBxWAN265sX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define model\n",
        "model1 = Sequential()\n",
        "\n",
        "# 1st Conv Layer\n",
        "model1.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
        "model1.add(Activation('relu'))\n",
        "\n",
        "# 2nd Conv Layer\n",
        "model1.add(Convolution2D(32, 3, 3))\n",
        "model1.add(Activation('relu'))\n",
        "\n",
        "# Max Pooling\n",
        "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "# Dropout\n",
        "model1.add(Dropout(0.2))\n",
        "\n",
        "# Fully Connected Layer\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(128))\n",
        "model1.add(Activation('relu'))\n",
        "\n",
        "# Prediction Layer\n",
        "model1.add(Dense(5))\n",
        "model1.add(Activation('softmax'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lhtm4d5K5sX1",
        "colab_type": "text"
      },
      "source": [
        "## Question 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmXg8EaF5sX2",
        "colab_type": "text"
      },
      "source": [
        "### Compile and fit the model\n",
        "- compile your model\n",
        "    - loss: \"categorical_crossentropy\"\n",
        "    - metrics: \"accuracy\"\n",
        "    - optimizer: \"sgd\"\n",
        "- fit your model\n",
        "    - give train data - features and labels\n",
        "    - batch size: 128\n",
        "    - epochs: 10\n",
        "    - give validation data - features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cgclxC8s5sX4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "8ca28862-b00a-40ba-d9ae-a4ef19a13b40"
      },
      "source": [
        "# Loss and Optimizer\n",
        "model1.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "# Store Training Results\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='auto')\n",
        "callback_list = [early_stopping]\n",
        "\n",
        "# Train the model2\n",
        "model1.fit(trainX_0_4, trainY_0_4, batch_size=128, nb_epoch=10,validation_split=0.1, callbacks=callback_list)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 27536 samples, validate on 3060 samples\n",
            "Epoch 1/10\n",
            "27536/27536 [==============================] - 2s 62us/step - loss: 0.0696 - acc: 0.9780 - val_loss: 0.0847 - val_acc: 0.9706\n",
            "Epoch 2/10\n",
            "27536/27536 [==============================] - 1s 51us/step - loss: 0.0666 - acc: 0.9784 - val_loss: 0.0729 - val_acc: 0.9739\n",
            "Epoch 3/10\n",
            "27536/27536 [==============================] - 1s 50us/step - loss: 0.0629 - acc: 0.9797 - val_loss: 0.0389 - val_acc: 0.9879\n",
            "Epoch 4/10\n",
            "27536/27536 [==============================] - 1s 51us/step - loss: 0.0591 - acc: 0.9816 - val_loss: 0.0383 - val_acc: 0.9876\n",
            "Epoch 5/10\n",
            "27536/27536 [==============================] - 1s 51us/step - loss: 0.0564 - acc: 0.9831 - val_loss: 0.0374 - val_acc: 0.9886\n",
            "Epoch 6/10\n",
            "27536/27536 [==============================] - 1s 52us/step - loss: 0.0520 - acc: 0.9831 - val_loss: 0.0373 - val_acc: 0.9886\n",
            "Epoch 7/10\n",
            "27536/27536 [==============================] - 1s 51us/step - loss: 0.0520 - acc: 0.9838 - val_loss: 0.0332 - val_acc: 0.9895\n",
            "Epoch 8/10\n",
            "27536/27536 [==============================] - 1s 51us/step - loss: 0.0486 - acc: 0.9850 - val_loss: 0.0323 - val_acc: 0.9902\n",
            "Epoch 9/10\n",
            "27536/27536 [==============================] - 1s 50us/step - loss: 0.0469 - acc: 0.9854 - val_loss: 0.0339 - val_acc: 0.9879\n",
            "Epoch 10/10\n",
            "27536/27536 [==============================] - 1s 52us/step - loss: 0.0442 - acc: 0.9865 - val_loss: 0.0362 - val_acc: 0.9889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fcaa59c93c8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSVZUu3p5sX5",
        "colab_type": "text"
      },
      "source": [
        "## Question 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5TQ3yLV5sX6",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate model\n",
        "- evaluate your model and get accuracy\n",
        "- use test features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBvuD3ba5sX7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "56091436-048b-4c41-af67-f9726a606035"
      },
      "source": [
        "scores = model1.evaluate(testX_0_4,testY_0_4, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 99.12%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aUzOh9m5sX-",
        "colab_type": "text"
      },
      "source": [
        "## Question 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srd-YYNH5sX-",
        "colab_type": "text"
      },
      "source": [
        "## Transfer learning\n",
        "Now we will apply this model on second dataset (5-9 digits)\n",
        "\n",
        "- fix the first convolution layers so that the weights in the convolution layers dont get updated in the process of training\n",
        "- get the second dataset\n",
        "- train the last 2 dense layers\n",
        "- predict the accuracy and loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvhdH7D55sYA",
        "colab_type": "text"
      },
      "source": [
        "### Make only dense layers trainable\n",
        "- set trainalble = False for all layers other than Dense layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j55eRl0JpmjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define model\n",
        "model1 = Sequential()\n",
        "\n",
        "# 1st Conv Layer\n",
        "model1.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
        "model1.trainable = False\n",
        "model1.add(Activation('relu'))\n",
        "model1.trainable = False\n",
        "# 2nd Conv Layer\n",
        "model1.add(Convolution2D(32, 3, 3))\n",
        "model1.trainable = False\n",
        "model1.add(Activation('relu'))\n",
        "model1.trainable = False\n",
        "# Max Pooling\n",
        "model1.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model1.trainable = False\n",
        "# Dropout\n",
        "model1.add(Dropout(0.2))\n",
        "model1.trainable = False\n",
        "# Fully Connected Layer\n",
        "model1.add(Flatten())\n",
        "model1.add(Dense(128))\n",
        "model1.add(Activation('relu'))\n",
        "\n",
        "# Prediction Layer\n",
        "model1.add(Dense(5))\n",
        "model1.add(Activation('softmax'))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYR9VGzO5sYE",
        "colab_type": "text"
      },
      "source": [
        "### Modify data\n",
        "- in your second data, class labels will start from 5 to 9 but for keras.utils.to_categorical the labels should start from 0\n",
        "- so you need to subtract 5 from train and test labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lC5W75L35sYF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "37531f7e-001d-4580-f6de-88f485368568"
      },
      "source": [
        "print(\"Shape of X_train_5_9 is - \",X_train_5_9.shape)\n",
        "print(\"Shape of y_train_5_9 is - \",y_train_5_9.shape)\n",
        "print(\"Shape of X_test_5_9 is - \",X_test_5_9.shape)\n",
        "print(\"Shape of X_test_5_9 is - \",y_test_5_9.shape)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of X_train_5_9 is -  (29404, 28, 28)\n",
            "Shape of y_train_5_9 is -  (29404,)\n",
            "Shape of X_test_5_9 is -  (4861, 28, 28)\n",
            "Shape of X_test_5_9 is -  (4861,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bc5OW74Trjm9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_5_9_new = []\n",
        "for i in range(0,y_train_5_9.shape[0]):\n",
        "      y_train_5_9_new.append((y_train_5_9[i]-5))\n",
        "\n",
        "y_train_5_9_new = np.array(y_train_5_9_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KSjlqRPrjaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_5_9_new = []\n",
        "for i in range(0,y_test_5_9.shape[0]):\n",
        "      y_test_5_9_new.append((y_test_5_9[i]-5))\n",
        "\n",
        "y_test_5_9_new = np.array(y_test_5_9_new)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTLJWqBbsxQS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6d3f9dea-bf30-4520-aed9-1d1fdeb16759"
      },
      "source": [
        "y_test_5_9[0]"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HaltFv33ri8V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2f6c2051-3176-462e-c557-cb429b9a9a0f"
      },
      "source": [
        "y_test_5_9_new[0]"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGY3OTBt5sYG",
        "colab_type": "text"
      },
      "source": [
        "### Reshape data\n",
        "- reshape second dataset\n",
        "- To be able to use the dataset in Keras, we need 4-dims numpy arrays. \n",
        "- reshape features to pass it to a Conv2D layer\n",
        "- channel = 1\n",
        "- reshape features of first dataset only\n",
        "- do not reshape labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0V7RUlRD5sYH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX_5_9 = X_train_5_9.reshape(X_train_5_9.shape[0], 28, 28,1 ).astype('float32')\n",
        "testX_5_9 = X_test_5_9.reshape(X_test_5_9.shape[0], 28, 28,1 ).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7omqMQH5sYJ",
        "colab_type": "text"
      },
      "source": [
        "### Normalize data\n",
        "- normalize second data\n",
        "- we must normalize our data as it is always required in neural network models\n",
        "- we can achieve this by dividing the RGB codes to 255 (which is the maximum RGB code minus the minimum RGB code)\n",
        "- normalize X_train and X_test\n",
        "- make sure that the values are float so that we can get decimal points after division"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEFYNHRp5sYJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX_5_9 /= 255\n",
        "testX_5_9 /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0OfdlF655sYM",
        "colab_type": "text"
      },
      "source": [
        "### Print shape of data and number of images\n",
        "- print shape of X_train\n",
        "- print number of images in X_train\n",
        "- print number of images in X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1094b514-a723-4d1c-e150-c28f55ab86d4",
        "id": "B2cv01cXtfJj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainX_5_9.shape"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(29404, 28, 28, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "65ef4850-3f92-4ff6-f9f9-d2caec44b69b",
        "id": "bMzau1DBtfJ5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainX_5_9.shape[0]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29404"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "ec5042f1-25d6-4a72-a403-eb246a904d9a",
        "id": "ec_oU2zCtfKC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "testX_5_9.shape[0]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4861"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_3-0Qwo5sYQ",
        "colab_type": "text"
      },
      "source": [
        "### One-hot encode the class vector\n",
        "- convert class vectors (integers) to binary class matrix\n",
        "- convert y_train and y_test\n",
        "- number of classes: 5\n",
        "- we are doing this to use categorical_crossentropy as loss\n",
        "\n",
        "Hint: you can use keras.utils.to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k46Me5Re5sYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        "trainY_5_9  = np_utils.to_categorical(y_train_5_9_new, 5)\n",
        "testY_5_9  = np_utils.to_categorical(y_test_5_9_new , 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9xEoW515sYS",
        "colab_type": "text"
      },
      "source": [
        "### Fit the model\n",
        "- give train data - features and labels\n",
        "- batch size: 128\n",
        "- epochs: 10\n",
        "- give validation data - features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B6f-XAc-5sYT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "3fb00afa-f9e9-44ef-9a11-4c584caa8382"
      },
      "source": [
        "# Loss and Optimizer\n",
        "model1.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
        "\n",
        "# Store Training Results\n",
        "early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=10, verbose=1, mode='auto')\n",
        "callback_list = [early_stopping]\n",
        "\n",
        "# Train the model2\n",
        "model1.fit(trainX_5_9, trainY_5_9, batch_size=128, nb_epoch=10,validation_split=0.1, callbacks=callback_list)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 26463 samples, validate on 2941 samples\n",
            "Epoch 1/10\n",
            "26463/26463 [==============================] - 2s 69us/step - loss: 0.8636 - acc: 0.7670 - val_loss: 0.2180 - val_acc: 0.9425\n",
            "Epoch 2/10\n",
            "26463/26463 [==============================] - 1s 51us/step - loss: 0.2511 - acc: 0.9180 - val_loss: 0.1583 - val_acc: 0.9595\n",
            "Epoch 3/10\n",
            "26463/26463 [==============================] - 1s 51us/step - loss: 0.1949 - acc: 0.9373 - val_loss: 0.1538 - val_acc: 0.9561\n",
            "Epoch 4/10\n",
            "26463/26463 [==============================] - 1s 51us/step - loss: 0.1707 - acc: 0.9464 - val_loss: 0.1186 - val_acc: 0.9694\n",
            "Epoch 5/10\n",
            "26463/26463 [==============================] - 1s 52us/step - loss: 0.1510 - acc: 0.9527 - val_loss: 0.1102 - val_acc: 0.9725\n",
            "Epoch 6/10\n",
            "26463/26463 [==============================] - 1s 50us/step - loss: 0.1369 - acc: 0.9558 - val_loss: 0.1036 - val_acc: 0.9728\n",
            "Epoch 7/10\n",
            "26463/26463 [==============================] - 1s 51us/step - loss: 0.1235 - acc: 0.9599 - val_loss: 0.0909 - val_acc: 0.9776\n",
            "Epoch 8/10\n",
            "26463/26463 [==============================] - 1s 53us/step - loss: 0.1156 - acc: 0.9630 - val_loss: 0.0848 - val_acc: 0.9799\n",
            "Epoch 9/10\n",
            "26463/26463 [==============================] - 1s 51us/step - loss: 0.1075 - acc: 0.9652 - val_loss: 0.0795 - val_acc: 0.9810\n",
            "Epoch 10/10\n",
            "26463/26463 [==============================] - 1s 52us/step - loss: 0.0975 - acc: 0.9684 - val_loss: 0.0784 - val_acc: 0.9803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fca3407fb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85ginrII5sYV",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate model\n",
        "- evaluate your model and get accuracy\n",
        "- use test features and labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k11-vrsm5sYW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f8b45fcd-2469-4ff9-9d6c-930d511c692a"
      },
      "source": [
        "scores = model1.evaluate(testX_5_9,testY_5_9, verbose=0)\n",
        "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 97.22%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTNhSDqn5sYY",
        "colab_type": "text"
      },
      "source": [
        "-----------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FU-HwvIdH0M-"
      },
      "source": [
        "# Sentiment analysis \n",
        "\n",
        "The objective of the second problem is to perform Sentiment analysis from the tweets collected from the users targeted at various mobile devices.\n",
        "Based on the tweet posted by a user (text), we will classify if the sentiment of the user targeted at a particular mobile device is positive or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIWWfNks5sYa",
        "colab_type": "text"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "nAQDiZHRH0M_"
      },
      "source": [
        "### Read the data\n",
        "- read tweets.csv\n",
        "- use latin encoding if it gives encoding error while loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H42emMyswgdb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "1fda7145-7579-4021-d144-235a42c91f72"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0eda9yqwyjQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "filepath = \"/content/drive/My Drive/AIML/NLP AND RECOMMENDED SYSTEMS/NLP PROJECT 1/tweets.csv\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sZwVmxww-yZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv(filepath,encoding = 'ISO-8859-1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qki1b4Kw-tW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ebd13818-b081-406d-c74c-784d9ff3970b"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9093, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNs5rbBRw-kU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c5db8bbb-d430-46c3-f7d6-e96eddb70b9c"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweet_text                                               1\n",
              "emotion_in_tweet_is_directed_at                       5802\n",
              "is_there_an_emotion_directed_at_a_brand_or_product       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdRCOwfqx824",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "9949a267-5cd2-4707-f1e8-ff1a986a8f66"
      },
      "source": [
        "df.head(6)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>@teachntech00 New iPad Apps For #SpeechTherapy...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>No emotion toward brand or product</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  ...                                   Negative emotion\n",
              "1  @jessedee Know about @fludapp ? Awesome iPad/i...  ...                                   Positive emotion\n",
              "2  @swonderlin Can not wait for #iPad 2 also. The...  ...                                   Positive emotion\n",
              "3  @sxsw I hope this year's festival isn't as cra...  ...                                   Negative emotion\n",
              "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  ...                                   Positive emotion\n",
              "5  @teachntech00 New iPad Apps For #SpeechTherapy...  ...                 No emotion toward brand or product\n",
              "\n",
              "[6 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4v4MvvIyCDj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bd0ceb2a-3888-4d15-fdc1-fbe9a5a52c44"
      },
      "source": [
        "df.is_there_an_emotion_directed_at_a_brand_or_product.unique()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Negative emotion', 'Positive emotion',\n",
              "       'No emotion toward brand or product', \"I can't tell\"], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39pqw0aE5sYe",
        "colab_type": "text"
      },
      "source": [
        "### Drop null values\n",
        "- drop all the rows with null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF_69oyI5sYf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bm4bDiy5sYg",
        "colab_type": "text"
      },
      "source": [
        "### Print the dataframe\n",
        "- print initial 5 rows of the data\n",
        "- use df.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ceSlvAVa5sYh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "045a3538-8efd-425e-ad94-e1374056cc1f"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  ...                                   Negative emotion\n",
              "1  @jessedee Know about @fludapp ? Awesome iPad/i...  ...                                   Positive emotion\n",
              "2  @swonderlin Can not wait for #iPad 2 also. The...  ...                                   Positive emotion\n",
              "3  @sxsw I hope this year's festival isn't as cra...  ...                                   Negative emotion\n",
              "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  ...                                   Positive emotion\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcWfPVqG5sYi",
        "colab_type": "text"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBbAeip_5sYj",
        "colab_type": "text"
      },
      "source": [
        "### Preprocess data\n",
        "- convert all text to lowercase - use .lower()\n",
        "- select only numbers, alphabets, and #+_ from text - use re.sub()\n",
        "- strip all the text - use .strip()\n",
        "    - this is for removing extra spaces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE4Bn_YT5sYj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "29b5fe8d-72c9-4b3f-855d-675966839817"
      },
      "source": [
        "import string , re\n",
        "import nltk,plotly\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "om-xnMVpytj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "REPLACE_BY_SPACE_RE = re.compile('[/(){}\\[\\]\\|@,;][‘’“”…]')\n",
        "BAD_SYMBOLS_RE = re.compile('[^0-9a-z #+_]')\n",
        "PUNCT_SYMBOLS_RE = re.compile('[%s]' % re.escape(string.punctuation))\n",
        "NUM_RE = re.compile('\\w*\\d\\w*') ## \\w = [a-zA-Z0-9_]  \\W = [^a-zA-Z0-9_]   -- Remove words containing numbers\n",
        "STOPWORDS = set(stopwords.words('english'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUFuv_rzytYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    \"\"\"\n",
        "        text: a string\n",
        "        \n",
        "        return: modified initial string\n",
        "    \"\"\"\n",
        "    text = text.lower() # lowercase text\n",
        "    text = text.strip() # for removing extra spaces \n",
        "\n",
        "     \n",
        "    text = REPLACE_BY_SPACE_RE.sub(' ', text) # replace REPLACE_BY_SPACE_RE symbols by space in text. substitute the matched string in REPLACE_BY_SPACE_RE with space.\n",
        "    text = BAD_SYMBOLS_RE.sub('', text) # remove symbols which are in BAD_SYMBOLS_RE from text. substitute the matched string in BAD_SYMBOLS_RE with nothing. \n",
        "    text = text.replace('x', '')\n",
        "    text = PUNCT_SYMBOLS_RE.sub('', text)\n",
        "    text = NUM_RE.sub('', text)\n",
        " \n",
        "   \n",
        "    text = ' '.join(word for word in text.split() if word not in STOPWORDS) # remove stopwors from text\n",
        "    #text = re.sub(r'\\W+', '', text)\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3eYinmiys-I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "d4413700-9941-4d0e-e100-f1337aa657bd"
      },
      "source": [
        "df.head(6)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>#SXSW is just starting, #CTIA is around the co...</td>\n",
              "      <td>Android</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  ...                                   Negative emotion\n",
              "1  @jessedee Know about @fludapp ? Awesome iPad/i...  ...                                   Positive emotion\n",
              "2  @swonderlin Can not wait for #iPad 2 also. The...  ...                                   Positive emotion\n",
              "3  @sxsw I hope this year's festival isn't as cra...  ...                                   Negative emotion\n",
              "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  ...                                   Positive emotion\n",
              "7  #SXSW is just starting, #CTIA is around the co...  ...                                   Positive emotion\n",
              "\n",
              "[6 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcSPizbj0D3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['tweet_text'] = df['tweet_text'].apply(clean_text)\n",
        "df['emotion_in_tweet_is_directed_at'] = df['emotion_in_tweet_is_directed_at'].apply(clean_text)\n",
        "df['is_there_an_emotion_directed_at_a_brand_or_product'] = df['is_there_an_emotion_directed_at_a_brand_or_product'].apply(clean_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JHKcbMh0K5h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "outputId": "a793e7b2-7efe-416e-9c84-695c48f961f2"
      },
      "source": [
        "df.head(6)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>iphone hrs tweeting riseaustin dead need upgra...</td>\n",
              "      <td>iphone</td>\n",
              "      <td>negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jessedee know fludapp awesome ipadiphone app y...</td>\n",
              "      <td>ipad iphone app</td>\n",
              "      <td>positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>swonderlin wait ipad also sale ssw</td>\n",
              "      <td>ipad</td>\n",
              "      <td>positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ssw hope years festival isnt crashy years ipho...</td>\n",
              "      <td>ipad iphone app</td>\n",
              "      <td>negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ststate great stuff fri ssw marissa mayer goog...</td>\n",
              "      <td>google</td>\n",
              "      <td>positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ssw starting ctia around corner googleio hop s...</td>\n",
              "      <td>android</td>\n",
              "      <td>positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0  iphone hrs tweeting riseaustin dead need upgra...  ...                                   negative emotion\n",
              "1  jessedee know fludapp awesome ipadiphone app y...  ...                                   positive emotion\n",
              "2                 swonderlin wait ipad also sale ssw  ...                                   positive emotion\n",
              "3  ssw hope years festival isnt crashy years ipho...  ...                                   negative emotion\n",
              "4  ststate great stuff fri ssw marissa mayer goog...  ...                                   positive emotion\n",
              "7  ssw starting ctia around corner googleio hop s...  ...                                   positive emotion\n",
              "\n",
              "[6 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlMvbtrK5sYl",
        "colab_type": "text"
      },
      "source": [
        "print dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afocjaUn5sYm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f0018114-7175-4a0e-975d-334b354360ef"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3291, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcTUnvtg5sYn",
        "colab_type": "text"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gnaeSXZ5sYo",
        "colab_type": "text"
      },
      "source": [
        "### Preprocess data\n",
        "- in column \"is_there_an_emotion_directed_at_a_brand_or_product\"\n",
        "    - select only those rows where value equal to \"positive emotion\" or \"negative emotion\"\n",
        "- find the value counts of \"positive emotion\" and \"negative emotion\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg9aF7_P5lW4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_new = df[((df['is_there_an_emotion_directed_at_a_brand_or_product'] == 'negative emotion')==True ) ^ ((df['is_there_an_emotion_directed_at_a_brand_or_product'] == 'positive emotion')==True )] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VFYB4eh5sYr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "6e1d28a3-c2dd-4dd4-819f-07a7eaa7ddf3"
      },
      "source": [
        "print(df_new.is_there_an_emotion_directed_at_a_brand_or_product.unique())\n",
        "print(df_new.shape)"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['negative emotion' 'positive emotion']\n",
            "(3191, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6icGcVTE5sYz",
        "colab_type": "text"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg0rSepj5sYz",
        "colab_type": "text"
      },
      "source": [
        "### Encode labels\n",
        "- in column \"is_there_an_emotion_directed_at_a_brand_or_product\"\n",
        "    - change \"positive emotion\" to 1\n",
        "    - change \"negative emotion\" to 0\n",
        "- use map function to replace values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWWP_xYD9jP_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "52ea2449-4de4-4ce4-c5f8-503df267a44e"
      },
      "source": [
        "df_new.head(5)"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>iphone hrs tweeting riseaustin dead need upgra...</td>\n",
              "      <td>iphone</td>\n",
              "      <td>negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jessedee know fludapp awesome ipadiphone app y...</td>\n",
              "      <td>ipad iphone app</td>\n",
              "      <td>positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>swonderlin wait ipad also sale ssw</td>\n",
              "      <td>ipad</td>\n",
              "      <td>positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ssw hope years festival isnt crashy years ipho...</td>\n",
              "      <td>ipad iphone app</td>\n",
              "      <td>negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ststate great stuff fri ssw marissa mayer goog...</td>\n",
              "      <td>google</td>\n",
              "      <td>positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0  iphone hrs tweeting riseaustin dead need upgra...  ...                                   negative emotion\n",
              "1  jessedee know fludapp awesome ipadiphone app y...  ...                                   positive emotion\n",
              "2                 swonderlin wait ipad also sale ssw  ...                                   positive emotion\n",
              "3  ssw hope years festival isnt crashy years ipho...  ...                                   negative emotion\n",
              "4  ststate great stuff fri ssw marissa mayer goog...  ...                                   positive emotion\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YftKwFv7H0N9",
        "colab": {}
      },
      "source": [
        "df_new['is_there_an_emotion_directed_at_a_brand_or_product'] = df_new['is_there_an_emotion_directed_at_a_brand_or_product'].map(lambda x: 1 if x=='positive emotion' else 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCmfC5iY-cvt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "ddf965bc-fe43-4aa1-957f-d62c181842a5"
      },
      "source": [
        "df_new.head(5)"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>iphone hrs tweeting riseaustin dead need upgra...</td>\n",
              "      <td>iphone</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jessedee know fludapp awesome ipadiphone app y...</td>\n",
              "      <td>ipad iphone app</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>swonderlin wait ipad also sale ssw</td>\n",
              "      <td>ipad</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ssw hope years festival isnt crashy years ipho...</td>\n",
              "      <td>ipad iphone app</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ststate great stuff fri ssw marissa mayer goog...</td>\n",
              "      <td>google</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0  iphone hrs tweeting riseaustin dead need upgra...  ...                                                  0\n",
              "1  jessedee know fludapp awesome ipadiphone app y...  ...                                                  1\n",
              "2                 swonderlin wait ipad also sale ssw  ...                                                  1\n",
              "3  ssw hope years festival isnt crashy years ipho...  ...                                                  0\n",
              "4  ststate great stuff fri ssw marissa mayer goog...  ...                                                  1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC1qSe3h5sY2",
        "colab_type": "text"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWlAN_Ts5sY2",
        "colab_type": "text"
      },
      "source": [
        "### Get feature and label\n",
        "- get column \"tweet_text\" as feature\n",
        "- get column \"is_there_an_emotion_directed_at_a_brand_or_product\" as label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A3sOZzR5sY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df_new['tweet_text']\n",
        "y = df_new['is_there_an_emotion_directed_at_a_brand_or_product']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3YErwYLCH0N_"
      },
      "source": [
        "### Create train and test data\n",
        "- use train_test_split to get train and test set\n",
        "- set a random_state\n",
        "- test_size: 0.25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lNkwrGgEH0OA",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVkLrXBjB7XB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state =2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMok2IX35sY8",
        "colab_type": "text"
      },
      "source": [
        "## Question 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSqYjPuT5sY8",
        "colab_type": "text"
      },
      "source": [
        "### Vectorize data\n",
        "- create document-term matrix\n",
        "- use CountVectorizer()\n",
        "    - ngram_range: (1, 2)\n",
        "    - stop_words: 'english'\n",
        "    - min_df: 2   \n",
        "- do fit_transform on X_train\n",
        "- do transform on X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb9PnnqT5sY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
        "# bag of words tool.  \n",
        "vectorizer = CountVectorizer(analyzer = \"word\", min_df=2,  \\\n",
        "                             tokenizer = None,    \\\n",
        "                             preprocessor = None, \\\n",
        "                             stop_words = 'english',   \\\n",
        "                             max_features = 5000) \n",
        "\n",
        "# fit_transform() does two functions: First, it fits the model\n",
        "# and learns the vocabulary; second, it transforms our training data\n",
        "# into feature vectors. The input to fit_transform should be a list of \n",
        "# strings.\n",
        "train_data_features = vectorizer.fit_transform(X_train)\n",
        "test_data_features = vectorizer.transform(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyQln8FyFHEg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "outputId": "7fffb9a3-52c8-463b-d149-4facc45897c1"
      },
      "source": [
        "\n",
        "# Numpy arrays are easy to work with, so convert the result to an \n",
        "# array  ## ,columns=train_data_features.get_feature_names()\n",
        "train_data_features_df = pd.DataFrame(train_data_features.toarray(),columns=vectorizer.get_feature_names())\n",
        "train_data_features_df"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aapl</th>\n",
              "      <th>able</th>\n",
              "      <th>absolutely</th>\n",
              "      <th>abt</th>\n",
              "      <th>access</th>\n",
              "      <th>aclu</th>\n",
              "      <th>aclugoogle</th>\n",
              "      <th>acquired</th>\n",
              "      <th>action</th>\n",
              "      <th>actsofsharingcom</th>\n",
              "      <th>actually</th>\n",
              "      <th>ad</th>\n",
              "      <th>add</th>\n",
              "      <th>added</th>\n",
              "      <th>addition</th>\n",
              "      <th>admit</th>\n",
              "      <th>admits</th>\n",
              "      <th>adoption</th>\n",
              "      <th>advertising</th>\n",
              "      <th>advisory</th>\n",
              "      <th>affirmative</th>\n",
              "      <th>afternoon</th>\n",
              "      <th>agents</th>\n",
              "      <th>agileagency</th>\n",
              "      <th>ago</th>\n",
              "      <th>agree</th>\n",
              "      <th>ah</th>\n",
              "      <th>ahead</th>\n",
              "      <th>ahhh</th>\n",
              "      <th>air</th>\n",
              "      <th>airline</th>\n",
              "      <th>airport</th>\n",
              "      <th>airports</th>\n",
              "      <th>aka</th>\n",
              "      <th>alarm</th>\n",
              "      <th>ale</th>\n",
              "      <th>alive</th>\n",
              "      <th>allow</th>\n",
              "      <th>allowing</th>\n",
              "      <th>alternate</th>\n",
              "      <th>...</th>\n",
              "      <th>world</th>\n",
              "      <th>worldand</th>\n",
              "      <th>worlds</th>\n",
              "      <th>worry</th>\n",
              "      <th>worst</th>\n",
              "      <th>worth</th>\n",
              "      <th>wouldnt</th>\n",
              "      <th>wow</th>\n",
              "      <th>wozniak</th>\n",
              "      <th>write</th>\n",
              "      <th>wrong</th>\n",
              "      <th>wrote</th>\n",
              "      <th>wsssw</th>\n",
              "      <th>wtf</th>\n",
              "      <th>yall</th>\n",
              "      <th>yay</th>\n",
              "      <th>yeah</th>\n",
              "      <th>year</th>\n",
              "      <th>years</th>\n",
              "      <th>yelp</th>\n",
              "      <th>yep</th>\n",
              "      <th>yes</th>\n",
              "      <th>yesterday</th>\n",
              "      <th>york</th>\n",
              "      <th>youd</th>\n",
              "      <th>youll</th>\n",
              "      <th>youre</th>\n",
              "      <th>youtube</th>\n",
              "      <th>youve</th>\n",
              "      <th>yr</th>\n",
              "      <th>yrs</th>\n",
              "      <th>yrsday</th>\n",
              "      <th>yup</th>\n",
              "      <th>zaggle</th>\n",
              "      <th>zappos</th>\n",
              "      <th>zazzlessw</th>\n",
              "      <th>zazzlssw</th>\n",
              "      <th>zms</th>\n",
              "      <th>zomg</th>\n",
              "      <th>zoom</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2388</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2389</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2390</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2391</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2392</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2393 rows × 2151 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      aapl  able  absolutely  abt  access  ...  zazzlessw  zazzlssw  zms  zomg  zoom\n",
              "0        0     0           0    0       0  ...          0         0    0     0     0\n",
              "1        0     0           0    0       0  ...          0         0    0     0     0\n",
              "2        0     0           0    0       0  ...          0         0    0     0     0\n",
              "3        0     0           0    0       0  ...          0         0    0     0     0\n",
              "4        0     0           0    0       0  ...          0         0    0     0     0\n",
              "...    ...   ...         ...  ...     ...  ...        ...       ...  ...   ...   ...\n",
              "2388     0     0           0    0       0  ...          0         0    0     0     0\n",
              "2389     0     0           0    0       0  ...          0         0    0     0     0\n",
              "2390     0     0           0    0       0  ...          0         0    0     0     0\n",
              "2391     0     0           0    0       0  ...          0         0    0     0     0\n",
              "2392     0     0           0    0       0  ...          0         0    0     0     0\n",
              "\n",
              "[2393 rows x 2151 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qanDXve15sY_",
        "colab_type": "text"
      },
      "source": [
        "## Question 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMaRNFkV5sY_",
        "colab_type": "text"
      },
      "source": [
        "### Select classifier logistic regression\n",
        "- use logistic regression for predicting sentiment of the given tweet\n",
        "- initialize classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT3dNgB55sZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import  linear_model\n",
        "\n",
        "lgr = linear_model.LogisticRegressionCV()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqQ6_HX35sZD",
        "colab_type": "text"
      },
      "source": [
        "### Fit the classifer\n",
        "- fit logistic regression classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIzvnNkq5sZD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "2937eade-1075-4823-c927-763d661f5c64"
      },
      "source": [
        "lgr.fit(train_data_features, y_train)"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegressionCV(Cs=10, class_weight=None, cv=None, dual=False,\n",
              "                     fit_intercept=True, intercept_scaling=1.0, l1_ratios=None,\n",
              "                     max_iter=100, multi_class='auto', n_jobs=None,\n",
              "                     penalty='l2', random_state=None, refit=True, scoring=None,\n",
              "                     solver='lbfgs', tol=0.0001, verbose=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZpMsYQF5sZF",
        "colab_type": "text"
      },
      "source": [
        "## Question 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGnQnUww5sZF",
        "colab_type": "text"
      },
      "source": [
        "### Select classifier naive bayes\n",
        "- use naive bayes for predicting sentiment of the given tweet\n",
        "- initialize classifier\n",
        "- use MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2H0EeqSlFyCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import  naive_bayes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "2AbVYssaH0OE",
        "colab": {}
      },
      "source": [
        "nb = naive_bayes.BernoulliNB()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEaG942m5sZI",
        "colab_type": "text"
      },
      "source": [
        "### Fit the classifer\n",
        "- fit naive bayes classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLwRBj1R5sZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a47db2a-c1f9-4198-8dec-c216d991cd18"
      },
      "source": [
        "nb.fit(train_data_features, y_train)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7mgwYDJ5sZM",
        "colab_type": "text"
      },
      "source": [
        "## Question 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZkA3tce5sZN",
        "colab_type": "text"
      },
      "source": [
        "### Make predictions on logistic regression\n",
        "- use your trained logistic regression model to make predictions on X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3f0M1ch5sZO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_lgr = lgr.predict(test_data_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrIxjMUB5sZQ",
        "colab_type": "text"
      },
      "source": [
        "### Make predictions on naive bayes\n",
        "- use your trained naive bayes model to make predictions on X_test\n",
        "- use a different variable name to store predictions so that they are kept separately"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSQnwyLU5sZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict_nb= nb.predict(test_data_features)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwXQUE7b5sZS",
        "colab_type": "text"
      },
      "source": [
        "## Question 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6SITIE75sZT",
        "colab_type": "text"
      },
      "source": [
        "### Calculate accuracy of logistic regression\n",
        "- check accuracy of logistic regression classifer\n",
        "- use sklearn.metrics.accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "clv2X0kKH0Ok",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6420857f-9b64-4252-ace3-8ba4aa730891"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "accuracy_score(predict_lgr,y_test)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.868421052631579"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fd_Gnd05sZV",
        "colab_type": "text"
      },
      "source": [
        "### Calculate accuracy of naive bayes\n",
        "- check accuracy of naive bayes classifer\n",
        "- use sklearn.metrics.accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d32uBpHi5sZW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "716ad254-c4bb-4275-8baa-60b14f07b80c"
      },
      "source": [
        "accuracy_score(predict_nb,y_test)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8734335839598998"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUDGoj93Iq3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}